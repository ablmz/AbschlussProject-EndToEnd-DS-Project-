{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping with Jupyter Notebook The Clinics Review Datas in Lower Saxsony Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Parojekt besteht aus drei Teile, und zwar:\n",
    "\n",
    "#### 1- Web Scraping                  :\n",
    "Beziehen von Rezensionen von den Seiten Klinikbewertungen.de & Google Maps\n",
    "#### 2- Data Science/Machine Learning :\n",
    "Bezogene & bereinigte Daten mittels einer Machine Learning Methode verarbeiten\n",
    "#### 3- Web Technologie               :\n",
    "Webseite/Webapp erstellen, um bezogene Daten und Ergebnisse des Machine Learnings darzustellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden nur Klinikbewertungen.de Daten verarbeitet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Web Scraping\n",
    "#### Beziehen von Rezensionen von den Seiten Klinikbewertungen.de & Google Maps\n",
    "\n",
    "\n",
    "#### Rahmen Klinikbewertungen:\n",
    "\n",
    "-\tzu erfassene Daten: Name der Klinik, Titel, Datum der Bewertung, Fachbereich, Sternebewertung (Gesamtzufriedenheit, Qualität der Beratung, Mediz. Behandlung, Verwaltung und Abläufe, Ausstattung und Gestaltung), Erfahrungsbericht und/oder Behandlungsjahr\n",
    "\n",
    "#### Ziel: Zwei Dateien mit den jeweiligen Bewertungen von Google Maps & Klinikbewertungen zur Weiterverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importieren der erforderlichen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import scrapy\n",
    "from scrapy.http import TextResponse\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Konvertieren Excel-Daten in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\name\\Desktop\\WB\\Abschlussproject\\Klinikliste.xlsx')\n",
    "df = pd.DataFrame(data, columns= ['Klinikname','Link Google Maps','Link Klinikbewertungen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren zu erfassene Daten unter clm Variable und erstellen Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name der Klinik</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Behandlungsjahr</th>\n",
       "      <th>Fachbereich</th>\n",
       "      <th>Erfahrungsbericht</th>\n",
       "      <th>Gesamtzufriedenheit</th>\n",
       "      <th>Qualität der Beratung</th>\n",
       "      <th>Mediz. Behandlung</th>\n",
       "      <th>Verwaltung und Abläufe</th>\n",
       "      <th>Ausstattung und Gestaltung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name der Klinik, Titel, Datum, Behandlungsjahr, Fachbereich, Erfahrungsbericht, Gesamtzufriedenheit, Qualität der Beratung, Mediz. Behandlung, Verwaltung und Abläufe, Ausstattung und Gestaltung]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clm=['Name der Klinik','Titel','Datum', 'Behandlungsjahr', 'Fachbereich','Erfahrungsbericht','Gesamtzufriedenheit','Qualität der Beratung','Mediz. Behandlung','Verwaltung und Abläufe','Ausstattung und Gestaltung']\n",
    "dataframe=pd.DataFrame(columns=clm)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 . Krankenhaus: Krankenhaus Marienstift Braunschweig  has a 2. Page\n",
      "3 . Krankenhaus: Herzogin Elisabeth Hospital Braunschweig  has a 2. Page\n",
      "4 . Krankenhaus: Asklepios Fachklinikum Göttingen  has a 2. Page\n",
      "5 . Krankenhaus: Asklepios Fachklinikum Tiefenbrunn  has a 2. Page\n",
      "6 . Krankenhaus: Friederikenstift Hannover  has a 2. Page\n",
      "7 . Krankenhaus: Annastift Hannover  has a 2. Page\n",
      "8 . Krankenhaus: Clementinenhaus  has a 2. Page\n",
      "9 . Krankenhaus: Sophienklinik Hannover  has a 2. Page\n",
      "10 . Krankenhaus: KRH Klinikum Großburgwedel  has a 2. Page\n",
      "11 . Krankenhaus: KRH Klinikum Lehrte  has a 2. Page\n",
      "12 . Krankenhaus: Krankenhaus Lindenbrunn  has a 2. Page\n",
      "13 . Krankenhaus: Krankenhaus Hameln  has a 2. Page\n",
      "15 . Krankenhaus: Helios Klinikum Hildesheim  has a 2. Page\n",
      "16 . Krankenhaus: AGAPLESION EV. KLINIKUM SCHAUMBURG  has a 2. Page\n",
      "17 . Krankenhaus: Helios Klinikum Cuxhaven  has a 2. Page\n",
      "18 . Krankenhaus: OsteMed Klinik Bremervörde  has a 2. Page\n",
      "19 . Krankenhaus: Klinik Fallingborstel  has a 2. Page\n",
      "20 . Krankenhaus: Klinikum Emden  has a 2. Page\n",
      "21 . Krankenhaus: Krankenhaus Ludmillenstift  has a 2. Page\n",
      "22 . Krankenhaus: Marienhospital Papenburg  has a 2. Page\n",
      "23 . Krankenhaus: Kreiskrankenhaus Osterholz  has a 2. Page\n"
     ]
    }
   ],
   "source": [
    "tt, dt, bj, fb, eb, gs, qb, mb, wa= [],[],[],[],[],[],[],[],[]\n",
    "\n",
    "for t in range (df.shape[0]):\n",
    "    \n",
    "    url = df.iloc[t,2]\n",
    "    r = requests.get(url)\n",
    "    response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if response.xpath(\"//div[@class='block']/p[@class='center']/a[@class='raquo button']/@href\").extract():\n",
    "        print(t+1, \". Krankenhaus:\", df.iloc[t,0], \" has a 2. Page\")\n",
    "        url=url+\"/bewertungen?allbew#more\" #second page's url has the only difference \"/bewertungen?allbew#more\" \n",
    "        r = requests.get(url) # so i added it and run again the code.\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        tt.append(response.xpath(\"//div[@class='list ratinglist']/article/header/h2/text()\").extract())\n",
    "        bj.append(response.xpath(\"////div[@class='meta']/text()[2]\"))\n",
    "        link = \"//span[@class='right']/a/text()\"\n",
    "        \n",
    "        if link:\n",
    "            link=link\n",
    "        else:\n",
    "            link=\"//div[@class='list ratinglist']/article/header/span/text()\"\n",
    "            \n",
    "        fb.append(response.xpath(link).extract())\n",
    "        eb.append(response.xpath(\"//p[@itemprop='reviewBody']\").extract())\n",
    "        gs.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[1]/text()\").extract())\n",
    "        qb.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[2]/text()\").extract())\n",
    "        mb.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[3]/text()\").extract())\n",
    "        wa.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[4]/text()\").extract())\n",
    "        #ag.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[5]/text()\").extract())\n",
    "        dt.append(response.xpath(\"//div[@class='meta']/time/text()\").extract())\n",
    "    else:\n",
    "        url = df.iloc[t,2]\n",
    "        tt.append(response.xpath(\"//div[@class='list ratinglist']/article/header/h2/text()\").extract())\n",
    "        bj.append(response.xpath(\"////div[@class='meta']/text()[2]\"))\n",
    "        #fb.append(response.xpath(\"//div[@class='list ratinglist']/article/span/a/text()\").getall())\n",
    "        fb.append(response.xpath(\"//span[@class='right']/a/text()\").extract())\n",
    "        eb.append(response.xpath(\"//p[@itemprop='reviewBody']\").extract())\n",
    "        gs.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[1]/text()\").extract())\n",
    "        qb.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[2]/text()\").extract())\n",
    "        mb.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[3]/text()\").extract())\n",
    "        wa.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[4]/text()\").extract())\n",
    "        #ag.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[5]/text()\").extract())\n",
    "        dt.append(response.xpath(\"//div[@class='meta']/time/text()\").extract())\n",
    "\n",
    "count1=0\n",
    "count1 = sum( [ len(elem) for elem in tt])\n",
    "count2=0\n",
    "count2 = sum( [ len(elem) for elem in eb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get all titel elements as a nested list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titel: 2999 Er.Bericht: 3000 Datum: 3000 Fachbch: 2389 G.Zufrdn: 3000 Qualität: 3000 M.Behand: 3000 wervaltng: 3000 B.Jahr: 3000\n"
     ]
    }
   ],
   "source": [
    "count1, count2, count3,count4,count5,count6,count7,count8,count9,count10=0,0,0,0,0,0,0,0,0,0\n",
    "count1 = sum( [ len(elem) for elem in tt])\n",
    "count2 = sum( [ len(elem) for elem in eb])\n",
    "#count3 = sum( [ len(elem) for elem in ag])\n",
    "count4 = sum( [ len(elem) for elem in dt])\n",
    "count5 = sum( [ len(elem) for elem in fb])\n",
    "count6 = sum( [ len(elem) for elem in gs])\n",
    "count7 = sum( [ len(elem) for elem in qb])\n",
    "count8 = sum( [ len(elem) for elem in mb])\n",
    "count9 = sum( [ len(elem) for elem in wa])\n",
    "count10 = sum( [ len(elem) for elem in bj])\n",
    "print(\"Titel:\",count1, \"Er.Bericht:\", count2, \"Datum:\", count4, \"Fachbch:\",count5, \"G.Zufrdn:\", count6, \"Qualität:\", count7, \"M.Behand:\", count8, \"wervaltng:\", count9, \"B.Jahr:\",count10)\n",
    "#\"Austtattung:\", count3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag=dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range (len(dt)):\n",
    "    for el in range(len(dt[x])):\n",
    "        ag[x][el]=\"Null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0):\n",
    "    for x in range(len(tt[i])):\n",
    "        #artikel=//*[contains(text(),tt[i][x])]/parent::*/parent::*\n",
    "        #agloc=//*[contains(text(),tt[i][x])]/parent::*/parent::*/section[@class='rating']/dl/dd[5]/text())\n",
    "        if response.xpath(\"//*[contains(text(),tt[i][x])]/parent::*/parent::*/section[@class='rating']/dl/dd[5]/text()\"):\n",
    "            ag[i][x]=response.xpath(\"//*[contains(text(),tt[i][x])]/parent::*/parent::*/section[@class='rating']/dl/dd[5]/text()\").extract()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null',\n",
       " 'Null']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sw=['Belastungsinkontinenz', 'Chirurgie 2 - klein und Ã¼bersichtlich', 'Noch immer ratlos und fassungslos', 'Mitspracherecht existiert eher als Papiertiger', 'Nette Schwestern.', 'Geburtsbericht Kaiserschnitt', 'Pflegeperspnal','Erstmal Urlaub machen', 'Besser geht nicht', 'Grottenschlechte Leistung', 'Alles super', 'UngenÃ¼gend','Krankenhaus oder Versuchslabor???'  ]\n",
    "for w in sw:\n",
    "    add=[(i, el.index(w)) for i, el in enumerate(tt) if w in el]\n",
    "    fb[add[0][0]].insert(add[0][1], \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ww=['kommt darauf an, was man hat und wer einen behandelt...','Mal wieder Krankenhaus', 'Entlassung/Wundversorgung','Wundversorgung', 'Einmalige Leistung in OHZ!' ]\n",
    "for w in ww:\n",
    "    add=[(i, el.index(w)) for i, el in enumerate(tt) if w in el]\n",
    "    ag[add[0][0]].insert(add[0][1], \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list=[tt, dt, bj, fb, eb, gs, qb, mb, wa, ag]\n",
    "for x in list:\n",
    "    #print(len(x))\n",
    "    for z in range(24):\n",
    "        print(len(x[z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe.to_csv(r'C:\\Users\\name\\Desktop\\WB\\Abschlussproject\\dataframeasim.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_json(r'C:\\Users\\name\\Desktop\\WB\\Abschlussproject\\dataframeasim.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Überschriften der Textuelle Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "titel=[]\n",
    "def extracttitel():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        #print(response)\n",
    "        titel.append(response.xpath(\"//div[@class='list ratinglist']/article/header/h2/text()\").extract())\n",
    "    return titel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Datum der Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=[]\n",
    "def extracttime():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        #print(response)\n",
    "        time.append(response.xpath(\"//div[@class='meta']/time/text()\").extract())\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Textuelle Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bewertungen=[]\n",
    "def extractbewertungen():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        #print(response)\n",
    "        bewertungen.append(response.xpath(\"//p[@itemprop='reviewBody']/text()\").extract())\n",
    "    return bewertungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fachbereich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bereich=[]\n",
    "def extractfachbereich():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        bereich.append(response.xpath(\"//div[@class='list ratinglist']/article/span/a/text()\").extract())\n",
    "    return bereich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sterne Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterne=[]\n",
    "def extractsterne():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        sterne.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[1]/text()\").extract())\n",
    "    return sterne\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterne=[]\n",
    "def extractsterne():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        sterne.append(response.xpath(\"//div[@class='list ratinglist']/article/section[@class='rating']/dl/dd[5]/text()\").extract())\n",
    "    return sterne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Erfahrungsbericht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "bericht=[]\n",
    "def extracterfahrungsbericht():\n",
    "    for i in range (df.shape[0]):\n",
    "        url = df.iloc[i,2]\n",
    "        r = requests.get(url)\n",
    "        response = TextResponse(r.url,body=r.text,encoding=\"utf-8\")\n",
    "        #response = response.replace(body=response.body.replace('<br>','\\n'))\n",
    "        #response = \"<br />\".join(response.split(\"\\n\"))\n",
    "        #response = response.replace(body=response.body.replace('<br />', '\\n')) \n",
    "        #bericht.append(response.xpath(\"//article[@class='bewertung']/section[@class='report']/dl/dd//*/text()\").extract())\n",
    "        #a= \" \".join(response.xpath(\"//p[@itemprop='reviewBody']/descendant::text() | following::text()\").extract())\n",
    "        #a= \" \".join(response.xpath(\"//p[@itemprop='reviewBody']/*[(self::script or self::style)]/text()\").extract())\n",
    "        #a= response.xpath(\"//p[@itemprop='reviewBody']\").extract()\n",
    "        a= response.xpath(\"//p[@itemprop='reviewBody']\").extract()\n",
    "        bericht.append(a)\n",
    "        #for t in response.xpath('//p[@itemprop='reviewBody']/text()'):\n",
    "            #bericht.append(t.xpath('string(.)').extract())\n",
    "    return bericht  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
